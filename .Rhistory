if (p_value <= 0.05){
cat("Significant relationship found between ",cont_var , "and " , cat_var,"with a p value ",p_value)
}
else {
cat("No significant relationship found between",cont_var,"and",cat_var, "with a p value", p_value)
}
}
}
perform_anova (data , 'price', c('cut','color','clarity','P','PC'))
perform_anova (cleaned_data , 'price', c('cut','color','clarity','P','PC'))
perform_anova <- function(data, cont_var , cat_vars){
for (cat_var in cat_vars){
anova_result <- aov(as.formula(paste(cont_var , '~' , cat_var )) , data = data)
summary_anova <-summary(anova_result)
p_value <- summary_anova [[1]]["Pr(>F)"][1, ]
if (p_value <= 0.05){
cat("Significant relationship found between ",cont_var , "and " , cat_var,"with a p value ",p_value)
}
else {
cat("No significant relationship found between",cont_var,"and",cat_var, "with a p value", p_value)
}
}
}
perform_anova (cleaned_data , 'price', c('cut','color','clarity','P','PC'))
perform_anova (cleaned_data , 'price', c('cut','clarity','P','PC'))
view(categorical_variable)
str(categorical_variable)
cleaned_data <- remove_outliers(data, c('carat','depth','price','x','y'))
View(cleaned_data)
View(cleaned_data)
#now we perform the anova test by creating a function
perform_anova <- function(data, cont_var , cat_vars){
for (cat_var in cat_vars){
anova_result  = aov(as.formula(paste(cont_var , '~' , cat_var )) , data = data)
summary_anova <- summary(anova_result)
p_value <- summary_anova [[1]]["Pr(>F)"][1, ]
if (p_value <= 0.05){
cat("Significant relationship found between ",cont_var , "and " , cat_var,"with a p value ",p_value)
}
else {
cat("No significant relationship found between",cont_var,"and",cat_var, "with a p value", p_value)
}
}
}
perform_anova (cleaned_data , 'price', c('cut','clarity','P','PC'))
perform_anova (cleaned_data , 'price', c('cut','color','clarity','P','PC'))
view(categorical_variable)
#our target variable is PRICE of diamonds- it is a continous variable
categorical_variable <- cleaned_data %>% select_if(is.character)
view(categorical_variable)
str(categorical_variable)
#now we perform the anova test by creating a function
perform_anova <- function(data, cont_var , cat_vars){
for (cat_var in cat_vars){
anova_result  = aov(as.formula(paste(cont_var , '~' , cat_var )) , data = data)
summary_anova <- summary(anova_result)
p_value <- summary_anova [[1]]["Pr(>F)"][1, ]
if (p_value <= 0.05){
cat("Significant relationship found between ",cont_var , "and " , cat_var,"with a p value ",p_value)
}
else {
cat("No significant relationship found between",cont_var,"and",cat_var, "with a p value", p_value)
}
}
}
perform_anova (cleaned_data , 'price', c('cut','colour','clarity','P','PC'))
###Between two continous variables ----
correlation_matrix <- cor(numeric_data)
correlation_matrix
##using pairs
pairs(cleaned_data[,c('x','y','carat','price','depth')])
##using pairs
pairs(cleaned_data[,c('x','y','carat','price','depth')])
##using pairs
pairs(cleaned_data[,c('x','y','carat','price','depth')])
##using correlation plot
corrplot(correlation_matrix, method = "circle")
###Between two categoricals----
view(cleaned_data)
#The "----" make the ide list the information
#pre processing ----
##Loading packages and librabries ----
install.packages("randomForest")
install.packages("xgboost")
library(tidyverse)
library(caret)
library(dplyr)
library(ggplot2)
library(corrplot)
library(randomForest)
library(xgboost)
##Loading the data----
setwd("/Users/keksmacbookair/Desktop/course works/R Programming/Practice R with Charles/R-practice")
data <-read.csv("pricingofDiamonds.csv")
#review few rows of the data ----
view (data)
head(data)
#view the structure of the data set----
str(data)#has ints ,chars and nums
#summary statistics
summary(data)#at this point we can use statistics to already tell if the data has outliers
##Handling missing values----
#approach one:----
missing_values <-sapply(data, function(x) sum(is.na(x)))#using a missing value function
missing_values
#no missing values in all columns
#approach two----
missing_values_2 <- data %>%summarise(numeric_missing = sum(is.na(.)),(categorical_missing = sum(is.na(as.character(.)))))#noint
missing_values_2
#approach 3 using dply ----
missing_values_3 <-data %>% summarise_all(funs(sum(is.na(.))))
missing_values_3
#a dot is neccessary for the code to run....
##Remove missing values----
##Drop missing values
#method 1 ----
data2 <-na.omit(data)
#method2(imputation with either mean,median or mode) ----
par(mfrow = c(2,1))## Helps get them all onto one page
hist(data$price, col = "blue", main = "Histogram for price")
hist(data$depth, col="blue", main = "Histogram for depth")
hist(data$x, col="blue", main = "Histogram for x")
#The graphs help tell us what we are to use on each specific variable , left skew = ,right skew = ,balanced = mean
##imputing----
###1,Continous data----
#With. mean (creating a function----
impute_mean <- function(x) replace(x,is.na(x), mean(x,na.rm = TRUE))
#with median ----
impute_median <- function(x) replace(x, is.na(x), median(x, na.rm = TRUE))
###2,CATEGORICAL VARIBLES
impute_mode <- function(x) {
model_value <-as.numeric(names(table(sort(x),decreasing = TRUE)[1]))##we convert the numeric variable into numeric so that it can be counted
##The true value is 1 cause in R it starts counting from the one value
replace(x,is.na(x),model_value)
}
#call the functions
impute_mean(data$depth)
impute_median(data$price)
#Approach three is using the mice function that technixally reates another data set----
imputed_data <- mice(data.m = 5, method ="pmm",maxit = 50, seed = 500)
install.packages("randomForest")
###Between two categoricals----
view(cleaned_data)
view(categorical_variable)
###Between two categoricals----
view(cleaned_data)
perform_chisq <-function(data,cat_var_1,cat_data){
for (cat_var_2 in cat_data) {
chisq_result = chisq.test(table(cleaned_data[[cat_var_1]], cleaned_data[[cat_var_2]]))
p_value <- chisq_result$p_value
if (p_value <= 0.05){
cat("Significant relationship found between",cat_var_1 ,"and", cat_var_2)
}
else {
cat("Significant relationship not found between", cat_var_1 ,"and",cat_var_2)
}
}
}
perform_chisq(cleaned_data,'colour',c('cut','clarity','P','PC'))
###Between two categoricals----
view(cleaned_data)
perform_chisq <-function(data,cat_var_1,cat_data){
for (cat_var_2 in cat_data) {
chisq_result = chisq.test(table(cleaned_data[[cat_var_1]], cleaned_data[[cat_var_2]]))
p_value <- chisq_result$p.value
if (p_value <= 0.05){
cat("Significant relationship found between",cat_var_1 ,"and", cat_var_2)
}
else {
cat("Significant relationship not found between", cat_var_1 ,"and",cat_var_2)
}
}
}
perform_chisq(cleaned_data,'colour',c('cut','clarity','P','PC'))
#####Creating the machine learning data ----
ml_data <-cleaned_data[,!names(cleaned_data) %in% c("depth","P","PC")]
head(ml_data)
#The "----" make the ide list the information
#pre processing ----
##Loading packages and librabries ----
install.packages("randomForest")
View(categorical_variable)
View(categorical_variable)
View(data)
View(data)
#The "----" make the ide list the information
#pre processing ----
##Loading packages and libraries ----
install.packages("randomForest")
install.packages("xgboost")
library(tidyverse)
library(caret)
library(dplyr)
library(ggplot2)
library(corrplot)
library(randomForest)
library(xgboost)
##Loading the data----
setwd("/Users/keksmacbookair/Desktop/course works/R Programming/Practice R with Charles/R-practice")
data <-read.csv("pricingofDiamonds.csv")
data <-read.csv("pricingofDiamonds.csv")
#review few rows of the data ----
view (data)
head(data)
*This is my practice space for R , iam going to go through all the various topics and subtopicsin r as quick as i can here*
#import the data set into r
# set a working directory
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
#install  necessary packages for data cleaning and visualization----
install.packages("tidyverse")
install.packages("dplyr")
install.packages("readxlsx")
install.packages("ggplot2")
#import the data set into r
# set a working directory----
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
install.packages("tidyverse")
#install  necessary packages for data cleaning and visualization----
install.packages("tidyverse")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("readxlsx")
install.packages("ggplot2")
#import the data set into r
# set a working directory----
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
##call the libraries to be used
library(readxl)
library(dplyr)
##call the data set
data = readxl::read_xls("Bike_Sales.xlsx")
library(xlsx)
library(Hmisc)
##call the data set
data = readxl::read_xlsx("Bike_Sales.xlsx")
#import the data set into r
# set a working directory----
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
getwd()
##call the data set
data <- read_xlsx("Bike_Sales.xlsx")
library(readxl)
Bike_Sales <- read_excel("~/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
View(Bike_Sales)
##call the data set
data <- read_excel("Bike_Sales.xlsx")
##call the data set
data <- read_excel("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
##we've renamed the data set as data
# viewing rows of data set----
view(data)
##we've renamed the data set as data
# viewing rows of data set----
view()
head(data, n=10)
summary(data)
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data, n=10)
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data)
##call the data set
data <- read.excel("Bike_Sales.xlsx")
##call the data set
data <- read.excel("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
##call the data set
data <- read_excel("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
library(dplyr)
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data)
tail(data)
dim(data)
summary(data)
names(data)#gives column names
glimpse(data)
View(data)
View(data)
## getting all the countries in the  dat set
data$Country
length(data$Country)
#for a continuos variable we are to get the mean median and range
mean(data$Customer_Age)
median(data$Customer_Age)
range(data$Customer_Age)
sum(is.na(data))
##Loading the data----
setwd("/Users/keksmacbookair/Desktop/course works/R Programming/Practice R with Charles/R-practice")
data <-read.csv("pricingofDiamonds.csv")
#review few rows of the data ----
view (data)
#review few rows of the data ----
view (data)
library(randomForest)
library(xgboost)
library(caret)
library(corrplot)
#review few rows of the data ----
view (data)
library(tidyverse)
library(randomForest)
library(xgboost)
library(dplyr)
#review few rows of the data ----
view (data)
head(data)
head(data,n=10)
#view the structure of the data set----
str(data)#has ints ,chars and nums
#summary statistics
summary(data)#at this point we can use statistics to already tell if the data has outliers
##Handling missing values----
#check for missing data
sum(is.na(data))
##### ASSIGNMENT 3: MARKING GUIDE #######
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
#QUESTION 1: Import data set (Vegetable_Sales.xlsx) and call it Assignment3_your_last_name (e.g. Assignment3_Kyalo) [1 MARK]
Assignment3_Kyalo = read_xlsx("Vegetable_Sales.xlsx")
#Import libraries
install.packages("read.excel")
#Import libraries
install.packages("read.excel")
library(readxl)
#QUESTION 1: Import data set (Vegetable_Sales.xlsx) and call it Assignment3_your_last_name (e.g. Assignment3_Kyalo) [1 MARK]
Assignment3_Kyalo = read_xlsx("Vegetable_Sales.xlsx")
##### ASSIGNMENT 3: MARKING GUIDE #######
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
getwd()
#QUESTION 1: Import data set (Vegetable_Sales.xlsx) and call it Assignment3_your_last_name (e.g. Assignment3_Kyalo) [1 MARK]
Assignment3_Kyalo = read_xlsx("Vegetable_Sales.xlsx")
#QUESTION 1: Import data set (Vegetable_Sales.xlsx) and call it Assignment3_your_last_name (e.g. Assignment3_Kyalo) [1 MARK]
Assignment3_Kyalo = read_xlsx("Vegetable_Sales1.xlsx")
#QUESTION 1: Import data set (Vegetable_Sales.xlsx) and call it Assignment3_your_last_name (e.g. Assignment3_Kyalo) [1 MARK]
Assignment3_Kyalo = read_xlsx("Vegetable_Sales-1.xlsx")
#QUESTION 2: Which is the highest selling vegetable? [1 MARK]
#First check the highest quantity sold (kg)
max(Assignment3_Kyalo$`Quantity Sold (kg)`)
#The maximum quantity sold is 1.321kg. So we use this to filter the data to figure out the vegetable that is most sold
Highest_Veg = filter(Assignment3_Kyalo, Assignment3_Kyalo$`Quantity Sold (kg)` == 1.321)
Highest_Veg
#Alternatively use a graph
plotA <- ggplot(Assignment3_Kyalo, aes(x = Assignment3_Kyalo$`Item Name`, y = Assignment3_Kyalo$`Quantity Sold (kg)`)) +
geom_point() +
theme_bw()
plotA
#Add labels to the plot
plotA + labs(x = "Vegetable Name", y = "Quantity Sold in kg") +
ggtitle("Vegetables sold in kg")
#QUESTION 3: How many  vegetables were sold on discount? [2 MARKS]
#Use the filter function within the variable "Sale or Return"
count(filter(Assignment3_Kyalo, Assignment3_Kyalo$`Discount (Yes/No)` == "yes"))
#QUESTION 4: Explain the descriptive statistics of the quantity of items sold in kg [2 MARKS]
summary(Assignment3_Kyalo$`Quantity Sold (kg)`)
shapiro.test(Assignment3_Kyalo$`Quantity Sold (kg)`)
#Alternatively use describe function
describe(Assignment3_Kyalo)
#QUESTION 5: Based on the “Loss Rate(%)”, which vegetable would you advise be removed from the supermarket shelves? [2 MARKS]
max(Assignment3_Kyalo$`Loss Rate (%)`)
#The highest loss rate is 29.25%. We use this to filter for the vegetable to be removed
Veg_Remove = filter(Assignment3_Kyalo, Assignment3_Kyalo$`Loss Rate (%)` == 29.25)
Veg_Remove
library(caTools)
library(rpart) #builds the model
library(rpart.plot) #plots the decision tree
library(ggplot2)
library(caret)
library(Boruta)
library(cvms)
library(dplyr)
library(MASS)
Assignment3_Kyalo$`Item Name` = as.factor(Assignment3_Kyalo$`Item Name`)
Assignment3_Kyalo$`Sale or Return` = as.factor(Assignment3_Kyalo$`Sale or Return`)
Assignment3_Kyalo$`Discount (Yes/No)` = as.factor(Assignment3_Kyalo$`Discount (Yes/No)`)
#ii) #Remove unnecessary columns if any (Item Code in my dataset)
Assignment3_Kyalo2 = subset(Assignment3_Kyalo, select = -(`Item Code`) )
#iii)Check relationships between categorical variables and the target "Discount"
#Use chisquare test
#Relationship between Item Name and Discount
Contigeny_table = table(Assignment3_Kyalo2$`Item Name`, Assignment3_Kyalo2$`Discount (Yes/No)`)
#View the table
Contigeny_table
#Then apply the chisquare test
print(chisq.test(Contigeny_table))
#Relationship between Sale or Return and Discount
Contigeny_table2 = table(Assignment3_Kyalo2$`Sale or Return`, Assignment3_Kyalo2$`Discount (Yes/No)`)
#View the table
Contigeny_table2
#Then apply the chisquare test
print(chisq.test(Contigeny_table2))
#Relationship between Loss Rate and Discount
#Use anova test
one.way = aov (`Loss Rate (%)` ~ `Discount (Yes/No)`, data = Assignment3_Kyalo2)
summary(one.way)
#Posthoc
TukeyHSD(one.way)
#iv) Split dataset leaving 70-80% to train the model, and 20-30% to test the model
set.seed(123)  # for reproducibility
train_indices <- sample(1:nrow(Assignment3_Kyalo2), 0.8 * nrow(Assignment3_Kyalo2))
train_data <- Assignment3_Kyalo2[train_indices, ]
test_data <- Assignment3_Kyalo2[-train_indices, ]
#The Discount (Yes/No) is the target variable
model <- rpart(`Discount (Yes/No)` ~ ., data = train_data, method = "class")
summary(model)
#Plot the decision tree of the model
library(rpart.plot)
rpart.plot(model)
## Plot the model with customized settings
rpart.plot(model, type = 3, box.palette = c("red", "green"), fallen.leaves = TRUE)
#v) Test the model on making predictions using the test data (20% of total dataset)
predictions <- predict(model, newdata = test_data, type = "class")
predictions
#Evaluate the performance of the model
table(predictions, test_data$`Discount (Yes/No)`)
accuracy <- sum(predictions == test_data$`Discount (Yes/No)`) / nrow(test_data)
print(paste("Accuracy:", accuracy))
#vi) Use the model to predict the Discount decision for the potato
Assignment3_Kyalo_test = read_xlsx("test_data.xlsx")
#Remove unnecessary columns if any (Item Code in my dataset)
Assignment3_Kyalo_test2 = subset(Assignment3_Kyalo_test, select = -(`Item Code`) )
Assignment3_Kyalo$`Item Name` = as.factor(Assignment3_Kyalo$`Item Name`)
Assignment3_Kyalo$`Sale or Return` = as.factor(Assignment3_Kyalo$`Sale or Return`)
Assignment3_Kyalo$`Discount (Yes/No)` = as.factor(Assignment3_Kyalo$`Discount (Yes/No)`)
#Use the model on the test dataset
model <- rpart(`Discount (Yes/No)` ~ ., data = Assignment3_Kyalo_test2, method = "class")
summary(model)
#Plot the decision tree of the model
library(rpart.plot)
rpart.plot(model)
#Set working directory
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
#install  necessary packages for data cleaning and visualization----
install.packages("tidyverse")
install.packages("dplyr")
install.packages("read.excel")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("ggplot2")
##call the libraries to be used
library(readxl)
library(dplyr)
library(Hmisc)
#import the data set into r
# set a working directory----
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
getwd()
##call the data set
data <- read_excel("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data)
str(data)
tail(data)
dim(data)#gives number of rows and columns
names(data)#gives column names
glimpse(data)#shows the structure of the data set..gives examples of values and data type
summary(data)
install.packages("ggplot2")
install.packages("tidyverse")
library(readxl)
library(dplyr)
library(Hmisc)
#import the data set into r
# set a working directory----
setwd("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets")
getwd()
##call the data set
data <- read_excel("/Users/keksmacbookair/Desktop/course work/Intro to Data science/data sets/Bike_Sales.xlsx")
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data)
##we've renamed the data set as data
# viewing rows of data set and getting a summary of the data----
head(data, n=5)
str(data)
dim(data)#gives number of rows and columns
names(data)#gives column names
glimpse(data)#shows the structure of the data set..gives examples of values and data type
summary(data)
## getting all the countries in the  dat set
data$Country
length(data$Country)#there are 113036 countries
#for a continuous variable we are to get the mean median and range
mean(data$Customer_Age)
median(data$Customer_Age)
range(data$Customer_Age)
sum(is.na(data))
View(data)
View(data)
##filterring out specific values(all males from the united states)
m_u = filter(data$Customer_Gender = "M",data$Country = "United States")
##filterring out specific values(all males from the united states)
m_u = filter(data, data$Customer_Gender == M,data$Country == United States)
##filterring out specific values(all males from the united states)
m_u = filter(data,data$Country == United States)
##filterring out specific values(all males from the united states)
mans = filter(data,data$Country == United States)
##filterring out specific values(all males from the united states)
mans = filter(data,data$Country == "United States")
mans
##filterring out specific values(all males from the united states)
mans = filter(data,data$Country == "United States",data$Customer_Gender =="M",data$Customer_Age >= 20)
mans
ggplot(data, aes(Customer_Age) + geom_point())
ggplot(data, aes(Customer_Age,Country, col=Sex) + geom_point())
ggplot(data, aes(Customer_Age,Country, col=Customer_Gender) + geom_point())
sum(is.na(data))
ggplot(data, aes(x = Customer_Age,y = Country, col=Customer_Gender) + geom_point())
ggplot(data, aes(x = Order_Quantity,y = Unit_Price) + geom_point())
ggplot(data, aes(x = Order_Quantity,y = Unit_Price)) + geom_point()
ggplot(data, aes(y = Order_Quantity,x = Unit_Price)) + geom_point()
ggplot(data, aes(y = Order_Quantity,x = Unit_Price)) + geom_point()+ geom_smooth(method=lm)
